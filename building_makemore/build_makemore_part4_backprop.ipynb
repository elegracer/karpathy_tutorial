{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a52d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there no change in the first several cells from last lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f61cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "974c0294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4520895b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(\"\".join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a4fcd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for w in words:\n",
    "        # print(w)\n",
    "        context = [0] * block_size\n",
    "        for ch in w + \".\":\n",
    "            idx = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(idx)\n",
    "            # print(\"\".join(itos[i] for i in context), \"--->\", itos[idx])\n",
    "            context = context[1:] + [idx] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71662f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok boilerplate done, now we get to the action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d423a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gredients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f\"{s:15s} |exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5f450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 just for fun\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden), generator=g) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden), generator=g) * 0.1\n",
    "\n",
    "# Note: I am initializing many of these parameters in non-standard ways\n",
    "# because somtimes intiializing with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc4bebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "idx = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[idx], Ytr[idx] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c0149b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5571, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n * hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-Linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "          bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "          embcat, emb]:\n",
    "    t.retain_grad()\n",
    "\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72a096da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        |exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           |exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  |exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      |exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          |exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     |exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     |exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          |exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               |exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              |exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              |exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         |exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "bngain          |exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "bnraw           |exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bnbias          |exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "bnvar_inv       |exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "bnvar           |exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bndiff2         |exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n",
      "bndiff          |exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bnmeani         |exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "hprebn          |exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "embcat          |exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
      "W1              |exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
      "b1              |exact: False | approximate: True  | maxdiff: 4.190951585769653e-09\n",
      "emb             |exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
      "C               |exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# excercise 1: backprop through the while thin manually,\n",
    "# backpropagating through exactly all of the variables\n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += 2*bndiff * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "dhprebn += (1.0/n)*torch.ones_like(hprebn) * dbnmeani\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0, keepdim=True)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        idx = Xb[k, j]\n",
    "        dC[idx] += demb[k, j]\n",
    "\n",
    "cmp(\"logprobs\", dlogprobs, logprobs)\n",
    "cmp(\"probs\", dprobs, probs)\n",
    "cmp(\"counts_sum_inv\", dcounts_sum_inv, counts_sum_inv)\n",
    "cmp(\"counts_sum\", dcounts_sum, counts_sum)\n",
    "cmp(\"counts\", dcounts, counts)\n",
    "cmp(\"norm_logits\", dnorm_logits, norm_logits)\n",
    "cmp(\"logit_maxes\", dlogit_maxes, logit_maxes)\n",
    "cmp(\"logits\", dlogits, logits)\n",
    "cmp(\"h\", dh, h)\n",
    "cmp(\"W2\", dW2, W2)\n",
    "cmp(\"b2\", db2, b2)\n",
    "cmp(\"hpreact\", dhpreact, hpreact)\n",
    "cmp(\"bngain\", dbngain, bngain)\n",
    "cmp(\"bnraw\", dbnraw, bnraw)\n",
    "cmp(\"bnbias\", dbnbias, bnbias)\n",
    "cmp(\"bnvar_inv\", dbnvar_inv, bnvar_inv)\n",
    "cmp(\"bnvar\", dbnvar, bnvar)\n",
    "cmp(\"bndiff2\", dbndiff2, bndiff2)\n",
    "cmp(\"bndiff\", dbndiff, bndiff)\n",
    "cmp(\"bnmeani\", dbnmeani, bnmeani)\n",
    "cmp(\"hprebn\", dhprebn, hprebn)\n",
    "cmp(\"embcat\", dembcat, embcat)\n",
    "cmp(\"W1\", dW1, W1)\n",
    "cmp(\"b1\", db1, b1)\n",
    "cmp(\"emb\", demb, emb)\n",
    "cmp(\"C\", dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f0f6a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5571467876434326 diff:  -2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), \"diff: \", (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b947ed41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          |exact: False | approximate: True  | maxdiff: 5.820766091346741e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp(\"logits\", dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4791ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0443, 0.0221, 0.0148, 0.0338, 0.0389, 0.0707, 0.0558, 0.0337, 0.0558,\n",
       "        0.0349, 0.0385, 0.0536, 0.0456, 0.0476, 0.0334, 0.0184, 0.0183, 0.0138,\n",
       "        0.0276, 0.0226, 0.0259, 0.0211, 0.0403, 0.0423, 0.0490, 0.0742, 0.0229],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25250d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0443, -0.9779,  0.0148,  0.0338,  0.0389,  0.0707,  0.0558,  0.0337,\n",
       "         0.0558,  0.0349,  0.0385,  0.0536,  0.0456,  0.0476,  0.0334,  0.0184,\n",
       "         0.0183,  0.0138,  0.0276,  0.0226,  0.0259,  0.0211,  0.0403,  0.0423,\n",
       "         0.0490,  0.0742,  0.0229], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcde6406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6566e-10, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52c40241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0691b2a7b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(dlogits.detach(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2077e183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: 4.76837158203125e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "# before:\n",
    "bnmeani = 1/n * hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print(f\"max diff: {(hpreact_fast - hpreact).abs().max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2276ecb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          |exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += 2*bndiff * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += (1.0/n)*torch.ones_like(hprebn) * dbnmeani\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n*(n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp(\"hprebn\", dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e9b3e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.9508\n",
      "  10000/ 200000: 2.3617\n",
      "  20000/ 200000: 2.2979\n",
      "  30000/ 200000: 2.2191\n",
      "  40000/ 200000: 2.5438\n",
      "  50000/ 200000: 2.1368\n",
      "  60000/ 200000: 2.2738\n",
      "  70000/ 200000: 1.9722\n",
      "  80000/ 200000: 1.8332\n",
      "  90000/ 200000: 2.5329\n",
      " 100000/ 200000: 2.1993\n",
      " 110000/ 200000: 2.3767\n",
      " 120000/ 200000: 2.3654\n",
      " 130000/ 200000: 2.4308\n",
      " 140000/ 200000: 2.3391\n",
      " 150000/ 200000: 2.1193\n",
      " 160000/ 200000: 2.0436\n",
      " 170000/ 200000: 2.0773\n",
      " 180000/ 200000: 2.0449\n",
      " 190000/ 200000: 2.2390\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 just for fun\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden), generator=g) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden), generator=g) * 0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# # use this context manager for efficiency once your backward pass is written (TODO)\n",
    "# with torch.no_grad():\n",
    "\n",
    "# kick off optimization\n",
    "for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "        for j in range(Xb.shape[1]):\n",
    "            ix = Xb[k,j]\n",
    "            dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "        # p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "        p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "        lossi.append(loss.log10().item())\n",
    "\n",
    "    # if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08557d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old:\n",
    "# 12297\n",
    "#       0/ 200000: 3.9508\n",
    "#   10000/ 200000: 2.3617\n",
    "#   20000/ 200000: 2.2979\n",
    "#   30000/ 200000: 2.2191\n",
    "#   40000/ 200000: 2.5438\n",
    "#   50000/ 200000: 2.1368\n",
    "#   60000/ 200000: 2.2738\n",
    "#   70000/ 200000: 1.9722\n",
    "#   80000/ 200000: 1.8332\n",
    "#   90000/ 200000: 2.5329\n",
    "#  100000/ 200000: 2.1994\n",
    "#  110000/ 200000: 2.3767\n",
    "#  120000/ 200000: 2.3654\n",
    "#  130000/ 200000: 2.4308\n",
    "#  140000/ 200000: 2.3390\n",
    "#  150000/ 200000: 2.1193\n",
    "#  160000/ 200000: 2.0436\n",
    "#  170000/ 200000: 2.0773\n",
    "#  180000/ 200000: 2.0449\n",
    "#  190000/ 200000: 2.2390\n",
    "\n",
    "# new:\n",
    "# 12297\n",
    "#       0/ 200000: 3.9508\n",
    "#   10000/ 200000: 2.3617\n",
    "#   20000/ 200000: 2.2979\n",
    "#   30000/ 200000: 2.2191\n",
    "#   40000/ 200000: 2.5438\n",
    "#   50000/ 200000: 2.1368\n",
    "#   60000/ 200000: 2.2738\n",
    "#   70000/ 200000: 1.9722\n",
    "#   80000/ 200000: 1.8332\n",
    "#   90000/ 200000: 2.5329\n",
    "#  100000/ 200000: 2.1993\n",
    "#  110000/ 200000: 2.3767\n",
    "#  120000/ 200000: 2.3654\n",
    "#  130000/ 200000: 2.4308\n",
    "#  140000/ 200000: 2.3391\n",
    "#  150000/ 200000: 2.1193\n",
    "#  160000/ 200000: 2.0436\n",
    "#  170000/ 200000: 2.0773\n",
    "#  180000/ 200000: 2.0449\n",
    "#  190000/ 200000: 2.2390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a98e5bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 10)        |exact: False | approximate: True  | maxdiff: 3.166496753692627e-08\n",
      "(30, 200)       |exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
      "(200,)          |exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "(200, 27)       |exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
      "(27,)           |exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "(1, 200)        |exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "(1, 200)        |exact: False | approximate: True  | maxdiff: 8.381903171539307e-09\n"
     ]
    }
   ],
   "source": [
    "# useful for checking your gradients\n",
    "for p, g in zip(parameters, grads):\n",
    "    cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2e53560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "    # pass the training set through\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    # measure the mean/std over the entire training set\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fb07a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0710816383361816\n",
      "val 2.111868143081665\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "        x, y = {\n",
    "            \"train\": (Xtr, Ytr),\n",
    "            \"val\": (Xdev, Ydev),\n",
    "            \"test\": (Xte, Yte),\n",
    "        }[split]\n",
    "        emb = C[x] # (N, block_size, n_embd)\n",
    "        embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "        hpreact = embcat @ W1 + b1\n",
    "        hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "        h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "        logits = h @ W2 + b2 # (N, vocab_size)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        print(split, loss.item())\n",
    "\n",
    "split_loss(\"train\")\n",
    "split_loss(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old\n",
    "# train 2.0710816383361816\n",
    "# val 2.111868143081665\n",
    "\n",
    "# new\n",
    "# train 2.0710816383361816\n",
    "# val 2.111868143081665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f9b449d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carlah.\n",
      "amelle.\n",
      "khi.\n",
      "mri.\n",
      "reigh.\n",
      "skanden.\n",
      "jazhitlalee.\n",
      "arci.\n",
      "aqui.\n",
      "ner.\n",
      "kea.\n",
      "chaiiv.\n",
      "kaleigh.\n",
      "ham.\n",
      "join.\n",
      "quinn.\n",
      "shoilea.\n",
      "jaddi.\n",
      "watell.\n",
      "dearyxia.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "\n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all\n",
    "    while True:\n",
    "        # -----------\n",
    "        # forward pass\n",
    "        # Embedding\n",
    "        emb = C[torch.tensor([context])] # (1, block_size, d)\n",
    "        embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "        hpreact = embcat @ W1 + b1\n",
    "        hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "        h = torch.tanh(hpreact) # (N, n_hiddne)\n",
    "        logits = h @ W2 + b2 # (N, vocab_size)\n",
    "        # ----------\n",
    "        # Sample\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        idx = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [idx]\n",
    "        out.append(idx)\n",
    "        if idx == 0:\n",
    "            break\n",
    "\n",
    "    print(\"\".join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old\n",
    "\n",
    "# carlah.\n",
    "# amelle.\n",
    "# khi.\n",
    "# mri.\n",
    "# reigh.\n",
    "# skanden.\n",
    "# jazhitlalee.\n",
    "# arci.\n",
    "# aqui.\n",
    "# ner.\n",
    "# kea.\n",
    "# chaiiv.\n",
    "# kaleigh.\n",
    "# ham.\n",
    "# join.\n",
    "# quinn.\n",
    "# shoilea.\n",
    "# jaddi.\n",
    "# watell.\n",
    "# dearyxia.\n",
    "\n",
    "# new\n",
    "\n",
    "# carlah.\n",
    "# amelle.\n",
    "# khi.\n",
    "# mri.\n",
    "# reigh.\n",
    "# skanden.\n",
    "# jazhitlalee.\n",
    "# arci.\n",
    "# aqui.\n",
    "# ner.\n",
    "# kea.\n",
    "# chaiiv.\n",
    "# kaleigh.\n",
    "# ham.\n",
    "# join.\n",
    "# quinn.\n",
    "# shoilea.\n",
    "# jaddi.\n",
    "# watell.\n",
    "# dearyxia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
